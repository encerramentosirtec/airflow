# Airflow com Cloudflare Tunnel via systemd ‚Äì Encerramento Sirtec

üéØ Orquestra fluxos de encerramento de processos/metas da Sirtec usando Apache Airflow.

Este projeto configura o Apache Airflow rodando em modo standalone e exposto atrav√©s de um t√∫nel Cloudflare, ambos gerenciados como servi√ßos `systemd` no Linux. Isso permite que o Airflow seja iniciado automaticamente com o sistema e acessado remotamente, mesmo sem IP p√∫blico.

#### Acesso ao Airflow

- O servi√ßo `tunnel.service` cria um t√∫nel p√∫blico usando o `trycloudflare.com` e salva o link gerado no arquivo `~/airflow/tunnel_link.txt`. Esse link pode ser acessado de qualquer lugar e redireciona para o `localhost:8080`, onde o Airflow est√° escutando.

## Estrutura do projeto

A raiz do projeto est√° localizada em `~/airflow`, que cont√©m os arquivos e scripts necess√°rios:

- `airenv/`: ambiente virtual Python com o Airflow instalado.
- `start_airflow.sh`: script que ativa o ambiente virtual e inicia o Airflow standalone.
- `start_tunnel.sh`: script que ativa o t√∫nel do Cloudflare e salva o link gerado.
- `airflow.log`: arquivo de log gerado pela execu√ß√£o do Airflow.
- `tunnel.log`: log da execu√ß√£o do t√∫nel.
- `tunnel_link.txt`: cont√©m o link p√∫blico gerado para acessar o Airflow via `trycloudflare.com`.


## üîß Requisitos
Python 3.8+

Apache Airflow 3.0+ (ou 2.6+)

## Instalar depend√™ncias (modo local):

### Criar venv
```
python -m venv nome_venv
```

### Ativar venv
Linux
```
source nome_venv/bin/activate
```
Windows
```
nome_venv/Scripts/activate
```

### Instalar depend√™ncias de requirements
```
pip install -r requirements.txt
```

## üöÄ Rodando o Airflow Localmente

Iniciar airflow
```
export AIRFLOW_HOME=~/caminho/para/airflow
airflow standalone
```

Criar tunnel
```
cloudflared tunnel --url http://localhost:8080
```

## üß† Comandos √öteis

```
airflow users create \
    --username admin \
    --firstname Admin \
    --lastname User \
    --role Admin \
    --email admin@example.com
airflow dags list
airflow dags trigger <dag_id>
airflow tasks test <dag_id> <task_id> <execution_date>
airflow dags pause <dag_id>
```

## ‚öôÔ∏è Configurar scripts para iniciar

Setar `.sh` como execut√°vel
```
chmod +x ~/airflow/start_airflow.sh
chmod +x ~/airflow/start_tunnel.sh
```

### Criando servi√ßo
- Tunnel
```
sudo nano /etc/systemd/system/airflow_tunnel.service
```

```
[Unit]
Description=Airflow + Cloudflared em tmux
After=network.target

[Service]
User=sirtec-fechamento
WorkingDirectory=/home/sirtec-fechamento/airflow
ExecStart=/usr/bin/tmux new-session -s airflow_tunnel /home/sirtec-fechamento/airflow/airflow_tunnel.sh
Restart=on-failure
Environment=TERM=xterm-256color
KillMode=process

[Install]
WantedBy=default.target

```

- Airflow
```
sudo nano /etc/systemd/system/airflow_standalone.service
```

```
[Unit]
Description=Airflow Standalone
After=network.target

[Service]
User=sirtec-fechamento
WorkingDirectory=/home/sirtec-fechamento/airflow
ExecStart=/home/sirtec-fechamento/airflow/start_airflow.sh
Environment=PYTHONPATH=/home/sirtec-fechamento/airflow
Restart=on-failure
Environment=TERM=xterm-256color
Environment=AIRFLOW_HOME=/home/sirtec-fechamento/airflow


[Install]
WantedBy=multi-user.target

```
### Ativar e iniciar

```
sudo systemctl daemon-reload
sudo systemctl enable airflow_tunnel.service
sudo systemctl enable airflow_standalone.service
sudo systemctl start airflow_tunnel.service
sudo systemctl start airflow_standalone.service
```

Ver logs:
```
journalctl -u airflow_tunnel.service -f
journalctl -u airflow_standalone.service -f
```

Parar o servi√ßo e desativar:
```
sudo systemctl stop airflow_tunnel.service
sudo systemctl disable airflow_tunnel.service
sudo systemctl stop airflow_standalone.service
sudo systemctl disable airflow_standalone.service
```
